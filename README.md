# ğŸ” Sistema de Busca Inteligente em Documentos com IA (LLM + RAG)

AplicaÃ§Ã£o web para busca semÃ¢ntica em documentos corporativos utilizando arquitetura **RAG (Retrieval-Augmented Generation)**.

O sistema permite que usuÃ¡rios faÃ§am perguntas em linguagem natural e recebam respostas fundamentadas no conteÃºdo real dos documentos internos da empresa.

---

## ğŸš€ VisÃ£o Geral

Este projeto implementa uma soluÃ§Ã£o de **IA aplicada Ã  gestÃ£o do conhecimento corporativo**, transformando documentos internos em uma base pesquisÃ¡vel por meio de linguagem natural.

A aplicaÃ§Ã£o:

- ğŸ“‚ LÃª documentos automaticamente (PDF, DOCX, TXT)
- ğŸ§  Gera embeddings vetoriais
- ğŸ“Š Cria um Ã­ndice vetorial
- ğŸ” Realiza busca semÃ¢ntica
- ğŸ¤– Gera respostas contextualizadas com LLM local

---

## ğŸ— Arquitetura da SoluÃ§Ã£o

### 1ï¸âƒ£ IngestÃ£o de Documentos
- Leitura automÃ¡tica da pasta `/documentos`
- ExtraÃ§Ã£o e estruturaÃ§Ã£o do texto

### 2ï¸âƒ£ GeraÃ§Ã£o de Embeddings
- Modelo `sentence-transformers/all-MiniLM-L6-v2`
- ConversÃ£o do texto em vetores semÃ¢nticos

### 3ï¸âƒ£ IndexaÃ§Ã£o Vetorial
- CriaÃ§Ã£o de `VectorStoreIndex`
- Armazenamento para recuperaÃ§Ã£o eficiente

### 4ï¸âƒ£ Pipeline RAG
- UsuÃ¡rio faz pergunta
- Sistema recupera trechos semanticamente relevantes
- LLM gera resposta fundamentada nos documentos

---

## ğŸ§  Stack TecnolÃ³gica

- Python  
- Streamlit  
- LlamaIndex  
- Ollama  
- Llama 3.2  
- HuggingFace Embeddings  

---

## ğŸ“‚ Estrutura do Projeto
